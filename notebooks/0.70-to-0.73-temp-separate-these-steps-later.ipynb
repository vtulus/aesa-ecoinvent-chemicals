{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This script is TEMPORTAL. Holds steps 0.40 to 0.83 <br>\n",
    "> Sources:\n",
    "  \n",
    "> Input file `data-regrouped-cpc-divisions-into-3-categories.xlsx` containing:\n",
    ">  * Sheet1: Extended data with chosen LCIA methods, important metadata and PubChem properties\n",
    ">  * METADATA: list of relevant metadata used in Sheet1.\n",
    ">  * METHODS: list of LCIA methods used in Sheet1.\n",
    "\n",
    "Note:\n",
    "> `data-regrouped-cpc-divisions-into-3-categories.xlsx` file was generated in `0.31-vt-regroup-cpc-divisions-into-3-categories.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env\n",
    "# %who_ls\n",
    "# %who\n",
    "# %who int\n",
    "# %pinfo <var name>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False # disable jedi autocompleter (https://stackoverflow.com/a/65734178/14485040)\n",
    "\n",
    "import project_path  # makes possible the access to `src` directory using relative path\n",
    "from src.data import (\n",
    "    create_glo_market,\n",
    "    filter_dataframe,\n",
    "    internal_funcs,\n",
    "    outlier_detectors,\n",
    ")\n",
    "from src.utils import explore_dir, make_readme_info\n",
    "from src.utils import read_excel_to_pandas as r_excel\n",
    "from src.utils import set_outputs_dir\n",
    "from src.utils import write_pandas_to_excel as w_excel\n",
    "\n",
    "%run init_nb.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUTS: Identify file(s) and read data to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the directory to find the file(s)\n",
    "inputs_dir, files_list = explore_dir(\n",
    "    path_to_dir=r\"..\\data\\interim\", file_extension=\"xlsx\", print_files_list=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df_cpc33to36 = r_excel(\n",
    "    inputs_dir, \"data-regrouped-cpc-divisions-into-3-categories.xlsx\"\n",
    ")\n",
    "print(\n",
    "    \"df_cpc33to36\".ljust(40, \".\"),\n",
    "    f\"{df_cpc33to36.shape}\\n\".rjust(13, \".\"),\n",
    ")\n",
    "\n",
    "# Get list of LCIA methods and list of metadata\n",
    "METHODS = r_excel(\n",
    "    inputs_dir,\n",
    "    \"data-regrouped-cpc-divisions-into-3-categories.xlsx\",\n",
    "    sheets=\"METHODS\",\n",
    "    show_readme=False, \n",
    ")[\"METHODS\"].values.tolist()\n",
    "\n",
    "METADATA = r_excel(\n",
    "    inputs_dir,\n",
    "    \"data-regrouped-cpc-divisions-into-3-categories.xlsx\",\n",
    "    sheets=\"METADATA\",\n",
    "    show_readme=False, \n",
    ")[\"METADATA\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Create mass allocated GLO markets from non-GLO markets\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "created: <code>df_analysis_extended</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_extended = create_glo_market(\n",
    "    df_in=df_cpc33to36,\n",
    "    columns_to_allocate=METHODS,\n",
    "    activity_column=\"Activity\",\n",
    "    refprod_column=\"referenceProduct\",\n",
    "    geo_column=\"geo\",\n",
    "    prodvol_column=\"referenceProduct_prodVolume\",\n",
    "    comment_column=\"activity_generalComment\",\n",
    ")\n",
    "\n",
    "print(\"Created **df_analysis_extended** dataframe is of {} shape.\".format(df_analysis_extended.shape))\n",
    "df_analysis_extended.tail(2)\n",
    "\n",
    "internal_funcs.plot_categories(\n",
    "    df_analysis_extended,\n",
    "    groupby=\"category_regrouped\",\n",
    "    cutoff_value=0,\n",
    "    color=\"purple\",\n",
    "    fontsize=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### Checks!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filter_dataframe(\n",
    "    df_in=df_analysis_extended,\n",
    "    col_name=\"referenceProduct\",\n",
    "    filter_in=comp_added_manually,\n",
    "#     filter_in=[\"Diesel\"],\n",
    "    exact_match=True,\n",
    ")\n",
    "\n",
    "# list(df_analysis_extended[df_analysis_extended.Activity==\"Diesel, combined to GLO market\"].activity_generalComment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### -- export to excel (activate if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Export dataframe to excel\n",
    "# excelName = \"df_to_analyze_extended_GLOmarkets.xlsx\"\n",
    "\n",
    "# df_readme = readme_data(\n",
    "#     excelName,\n",
    "#     \"Dataframe similar to df_to_analyze.xlsx [(selected) metadata of chemical markets and scores for multiple LCIA methods], but with additional GLO chemical markets, obtained from mass allocation of respective non-GLO markets.\",\n",
    "# )\n",
    "\n",
    "# writedf_to_Excel(\n",
    "#     path_to_file=outputsDir,\n",
    "#     filename=excelName,\n",
    "#     sheetname_and_data={\"Sheet1\": df_analysis_extended}, \n",
    "#     readme_data={\"readme\":df_readme},\n",
    "# #     ExcelWriter_kwargs={\"engine\": \"openpyxl\", \"encoding\": \"UTF-8\"}\n",
    "# #     startrow=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# lst_all_method_labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Check if items in potentially duplicated columns are the same\n",
    "any(\n",
    "    ~(df_master_raw.shortName_geo == df_master_raw.geo)\n",
    ")  # any not equal items in both columns?\n",
    "any(\n",
    "    ~(df_master_raw.fullName_SimaPro == df_master_raw.Activity)\n",
    ")  # any not equal items in both columns?\n",
    "any(\n",
    "    ~(df_master_raw.unit == df_master_raw.referenceProductUnit)\n",
    ")  # any not equal items in both columns?\n",
    "any(\n",
    "    ~(df_master_raw.amount == df_master_raw.referenceProductAmount)\n",
    ")  # any not equal items in both columns?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# checks: are the column values identical? ---> redundant\n",
    "all(df_master_raw.unit == df_master_raw.referenceProductUnit)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# filter_dataframe(df_master_raw, 'unit_intExchange', filter_out=['kg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Created dfs to work with: `df_base_full` and `df_base_full_wCAS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create df_base only with GLO markets and individual FU=kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df_analysis_extended[\n",
    "    (df_analysis_extended.geo == \"GLO\")\n",
    "    & (df_analysis_extended.referenceProductUnit == \"kg\")\n",
    "]# .shape\n",
    "\n",
    "\n",
    "# # Group by shortName_geo_SP -> filter by GLO -> Filter \"unit\" by \"kg\"\n",
    "# df_base = _filter_by_geo_and_FU(\n",
    "# #     df=df_analysis,\n",
    "#     df=df_analysis_extended,\n",
    "#     geo=\"GLO\", \n",
    "#     FU=\"kg\"\n",
    "# )\n",
    "print(\"Created **df_base** dataframe is of {} shape.\\n\".format(df_base.shape))\n",
    "# df_base\n",
    "\n",
    "# Grouping by 'category' and ploting the size of each group on a barh plot (in one line)\n",
    "internal_funcs.plot_categories(\n",
    "    df_in=df_base,\n",
    "    groupby=\"category_regrouped\",   \n",
    "    color=\"blue\", \n",
    "    fontsize=12,\n",
    "    cutoff_value=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products excluded from the analysis\n",
    "internal_funcs.excluded_products(\n",
    "    df_raw=df_analysis_extended, # or =df_analysis_extended, (both have the same nÂº of unique products)\n",
    "    df_filtered=df_base\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add transgression levels (TLs) to df_base\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "created: <strong>df_base_full and df_base_full_wCAS</strong>  \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct methods name for TLs... add lst_methods_TLs\n",
    "lst_methods_TLs = lst_methods_TLs = [\"TL in \" + sub for sub in lst_methods[1:]]\n",
    "lst_methods_TLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create `df_base_full` with ALL activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_full = pd.concat(\n",
    "    [\n",
    "        df_base,\n",
    "        calculate_TL_PBs(\n",
    "            df_base,\n",
    "            method_labels=lst_methods[1:],\n",
    "            price_column=\"referenceProduct_price\",\n",
    "            GVA_world = 7.38e13, # in 2018\n",
    "            correctGVA=None,\n",
    "#             correctGVA=\"sales\",\n",
    "#             correctGVA=\"purchases\",\n",
    "#             share_of_SOS=0.0689, # aggregated shares of 4 sectors (C19-22) using GGG method\n",
    "#             share_of_SOS=0.0237, # only C20 sector using GGG method\n",
    "#             share_of_SOS=0.0274, # aggregated shares of 4 sectors (C19-22) using WIOD with L inverse\n",
    "#             share_of_SOS=0.0076, # only C20 sector using WIOD with L inverse\n",
    "        ).add_prefix(\"TL in \"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "print(\"Created **df_base_full** dataframe is of {} shape.\\n\".format(df_base_full.shape))\n",
    "df_base_full.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert prices from EUR2005 to USD2018\n",
    "# using this unit the TLs were calculated !!!\n",
    "PPI_2018 = 104.5 # Producer Price Index from Eurostat\n",
    "PPI_2005 = 86.0  # Producer Price Index from Eurostat\n",
    "USD_per_EUR_2018 = 1.1811 # average exchange rate EUR to USD in 2018\n",
    "\n",
    "df_base_full.referenceProduct_price = (df_base_full.referenceProduct_price * PPI_2018 / PPI_2005) * USD_per_EUR_2018\n",
    "df_base_full.referenceProduct_priceUnit = \"USD2018\"\n",
    "df_base_full.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'category_regrouped' and ploting the size of each group on a barh plot (in one line)\n",
    "internal_funcs.plot_categories(\n",
    "    df_in=df_base_full,\n",
    "    groupby=\"category_regrouped\",\n",
    "    color=\"green\",\n",
    "    fontsize=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_full[df_base_full.referenceProduct == 'Cyclic N-compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Export dataframe to excel\n",
    "# excelName = \"df_base_full.xlsx\"\n",
    "\n",
    "# df_readme = readme_data(\n",
    "#     excelName,\n",
    "#     \"Dataframe df_base_full - all GLO markets with PBs and TLs.\",\n",
    "# )\n",
    "\n",
    "# writedf_to_Excel(\n",
    "#     path_to_file=outputsDir,\n",
    "#     filename=excelName,\n",
    "#     sheetname_and_data={\"Sheet1\": df_base_full}, \n",
    "#     readme_data={\"readme\":df_readme},\n",
    "# #     ExcelWriter_kwargs={\"engine\": \"openpyxl\", \"encoding\": \"UTF-8\"}\n",
    "# #     startrow=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create `df_base_full_wCAS` ONLY with activities detected in PubChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_full_wCAS = df_base_full[df_base_full.num_matches != 0]\n",
    "\n",
    "print(\"Created **df_base_full_wCAS** dataframe is of {} shape.\\n\".format(df_base_full_wCAS.shape))\n",
    "df_base_full_wCAS.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'category_regrouped' and ploting the size of each group on a barh plot (in one line)\n",
    "internal_funcs.plot_categories(\n",
    "    df_in=df_base_full_wCAS,\n",
    "    groupby=\"category_regrouped\",\n",
    "    color=\"darkorange\",\n",
    "    fontsize=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `highlighted_product` list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### research possible highlighted products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_known_chemicals = [\n",
    "    \"Toluene\",\n",
    "    \"Xylene\",\n",
    "    # Javier's list below\n",
    "    \"Liquefied petroleum gas\",  # ok\n",
    "    \"Petrol\",  # \"Gasoline\", # ok\n",
    "    \"Diesel\",  # ok\n",
    "    \"Kerosene\",  # ok\n",
    "    \"Ethylene\",  # ok\n",
    "    \"Propylene\",  # ok\n",
    "    \"Benzene\",  # ok\n",
    "    \"Synthetic gas\",  # FU 1m3\n",
    "    \"Ammonia, liquid\",  # ok\n",
    "    \"Methanol\",  # ok\n",
    "    \"Sulfuric acid\",  # ok\n",
    "    \"Chlorine\",  # ok\n",
    "    \"Acetic acid\",  # ok\n",
    "    \"Formaldehyde\",  # ok\n",
    "    \"Urea\",  # ok\n",
    "    \"Ethylene oxide\",  # ok\n",
    "    \"Acrylonitrile\",  # ok\n",
    "    \"Acetaldehyde\",  # ok\n",
    "    \"Polyethylene\",  # ok\n",
    "    \"Polypropylene\",  # ok\n",
    "    \"Polyvinylchloride\",  # ok\n",
    "    \"Hydrogen\",  # ok\n",
    "]\n",
    "\n",
    "for item in lst_known_chemicals:\n",
    "    print(\"Looking for \" + item)\n",
    "    filter_dataframe(\n",
    "        df_analysis_extended,\n",
    "        col_name=\"referenceProduct\",\n",
    "        filter_in=[item],\n",
    "        print_unique=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selected products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact names only!\n",
    "\n",
    "highlighted_product = [\n",
    "    \"Sulfuric acid\",\n",
    "    \"Kerosene\",\n",
    "    \"Diesel, low-sulfur\", # or \"Diesel\",\n",
    "    \"Liquefied petroleum gas\",\n",
    "    \"Methanol\",\n",
    "    \"Petrol, low-sulfur\",\n",
    "    \"Formaldehyde\",\n",
    "    \"Chlorine, liquid\",\n",
    "    \"Ethylene, average\",\n",
    "    \"Propylene\",\n",
    "    \"Toluene, liquid\",\n",
    "    \"Acetic acid, without water, in 98% solution state\",\n",
    "    \"Acetaldehyde\",\n",
    "    \"Polyethylene, high density, granulate\",\n",
    "    \"Benzene\",\n",
    "    \"Ammonia, liquid\",\n",
    "    \"Polypropylene, granulate\",\n",
    "    \"Ethylene oxide\",\n",
    "    \"Polyvinylchloride, bulk polymerised\",\n",
    "    \"Hydrogen, liquid\",\n",
    "    \"Acrylonitrile\",\n",
    "    \"Urea, as N\",\n",
    "    \"1-propanol\",\n",
    "    \"Acetylene\",\n",
    "    \"Chlorotoluron\",\n",
    "    \"Methylene diphenyl diisocyanate\",\n",
    "    \"Ammonium nitrate, as N\",\n",
    "    \"Pyridine\",\n",
    "    \"Nylon 6-6\",\n",
    "    \"Glyphosate\",\n",
    "    \"Para-phenylene diamine\",\n",
    "    \"Fluorine, liquid\",\n",
    "    \"Adipic acid\",\n",
    "    \"Xylene\"\n",
    "]\n",
    "\n",
    "selected = internal_funcs.find_chemicals(\n",
    "    df_base_full,\n",
    "#     df_base_full_wCAS,\n",
    "    highlighted_product,\n",
    "    colname=\"referenceProduct\",\n",
    ")[\n",
    "    [\"Activity\"]\n",
    "    + [\"referenceProduct\"]\n",
    "    + [\"geo\"]\n",
    "    #     + [\"category\"]\n",
    "        + [\"category_regrouped\"]\n",
    "    + [\"referenceProduct_CPCclass\"]\n",
    "    #     + [\"referenceProduct_prodVolume\"]\n",
    "    + [\"('IPCC 2013 GWP 100a V1.03', 'IPCC GWP 100a', 'kg CO2 eq')\"]\n",
    "    #     + [\"complexity\"]\n",
    "        + [\"MF\"]\n",
    "    #     lst_metadata\n",
    "    #     + lst_methods\n",
    "]\n",
    "\n",
    "selected[selected.geo == \"GLO\"].sort_values(\n",
    "    by=\"('IPCC 2013 GWP 100a V1.03', 'IPCC GWP 100a', 'kg CO2 eq')\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make df of highlighted_product for later export\n",
    "df_highlighted_product = pd.DataFrame(highlighted_product, columns=[\"highlighted_product\"])\n",
    "# df_highlighted_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### -- export to excel (activate if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Export dataframe to excel\n",
    "# excelName = \"df_GLO_markets.xlsx\"\n",
    "\n",
    "# df_readme = readme_data(\n",
    "#     excelName,\n",
    "#     \"Filtered dataframe includes only GLO chemical markets with FU = 1kg\",\n",
    "# )\n",
    "\n",
    "# writedf_to_Excel(\n",
    "#     path_to_file=outputsDir,\n",
    "#     filename=excelName,\n",
    "#     sheetname_and_data={\"Sheet1\": df_base}, \n",
    "#     readme_data={\"readme\":df_readme},\n",
    "# #     ExcelWriter_kwargs={\"engine\": \"openpyxl\", \"encoding\": \"UTF-8\"}\n",
    "# #     startrow=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtering outliers\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "use previously created:  <br>\n",
    "    <strong>df_base_full</strong> - only GLO, kg markets from CPC 33-36  <br>\n",
    "    <strong>ddf_base_full_wCAS</strong> - only GLO, kg markets from CPC 33-36 with identified chemical properties (could be refined!)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### apply Mahalanobis Distance method to detect outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_to_detect_MDm = df_base_full\n",
    "df_to_detect_MDm = df_base_full_wCAS\n",
    "\n",
    "(\n",
    "    df_clean_metNtlNpr_MDm,\n",
    "    df_outliers_metNtlNpr_MDm,\n",
    "    more_metNtlNpr_MDm,\n",
    ") = outlier_detectors.mahalanobis_method(\n",
    "    df_raw=df_to_detect_MDm[\n",
    "        lst_methods[0:1]\n",
    "        + lst_methods[1:]\n",
    "        + lst_methods_TLs\n",
    "        + [\"referenceProduct_price\"]\n",
    "    ],\n",
    "    alpha=(1 - 0.95),\n",
    ")\n",
    "print(\"out of\", df_to_detect_MDm.shape[0], \"items\")\n",
    "print(len(more_metNtlNpr_MDm[0]), \"outliers detected\")\n",
    "\n",
    "outlier_detectors.make_full_df_after_outlier_detection_method(\n",
    "    df_to_detect_MDm, df_outliers_metNtlNpr_MDm\n",
    ")[\n",
    "    [\"referenceProduct\"]\n",
    "    + [lst_methods[0]]\n",
    "    + [lst_methods_TLs[0]]\n",
    "    + [\"referenceProduct_price\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base_full_wCAS[\n",
    "#     df_base_full_wCAS[\"('IPCC 2013 GWP 100a V1.03', 'IPCC GWP 100a', 'kg CO2 eq')\"]\n",
    "#     > 1000\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'category_regrouped' and ploting the size of each group on a barh plot (in one line)\n",
    "\n",
    "df_base_full_wCAS_woOutliersMDk20a5 = outlier_detectors.make_full_df_after_outlier_detection_method(\n",
    "    df_to_detect_MDm, df_clean_metNtlNpr_MDm\n",
    ")\n",
    "\n",
    "internal_funcs.plot_categories(\n",
    "    df_in=df_base_full_wCAS_woOutliersMDk20a5,\n",
    "    groupby=\"category_regrouped\",\n",
    "    color=\"darkorange\",\n",
    "    fontsize=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### apply Robust Mahalanobis Distance method to detect outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_to_detect_RMDm = df_base_full\n",
    "df_to_detect_RMDm = df_base_full_wCAS\n",
    "\n",
    "(\n",
    "    df_clean_metNtlNpr_RMDm,\n",
    "    df_outliers_metNtlNpr_RMDm,\n",
    "    more_metNtlNpr_RMDm,\n",
    ") = outlier_detectors.robust_mahalanobis_method(\n",
    "    df_to_detect_RMDm[\n",
    "        #         lst_methods\n",
    "        #         +\n",
    "        lst_methods_TLs\n",
    "        #         + [\"referenceProduct_price\"]\n",
    "    ],\n",
    "    alpha=(1 - 0.95),\n",
    "    support_fraction=None,\n",
    ")\n",
    "print(\"out of\", df_to_detect_RMDm.shape[0], \"items\")\n",
    "print(len(more_metNtlNpr_RMDm[0]), \"outliers detected\")\n",
    "\n",
    "outlier_detectors.make_full_df_after_outlier_detection_method(\n",
    "    df_to_detect_RMDm, df_outliers_metNtlNpr_RMDm\n",
    ")[\n",
    "    [\"referenceProduct\"]\n",
    "    + [lst_methods[0]]\n",
    "    + [lst_methods_TLs[0]]\n",
    "    + [\"referenceProduct_price\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = df_base_full_wCAS.loc[more_metNtlNpr_RMDm[0],:][\n",
    "    lst_metadata[0:1]\n",
    "    + lst_metadata[4:5]\n",
    "#     + [\"referenceProduct_price\"]\n",
    "#     + lst_methods[0:1]\n",
    "    + lst_methods_TLs\n",
    "]\n",
    "# df_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set output directory\n",
    "outputs_dir = set_outputs_dir(use_default=True)  # default `..\\data\\interim`\n",
    "\n",
    "## Export dataframe to excel\n",
    "excelName = \"list-outliers.xlsx\"\n",
    "\n",
    "df_readme = make_readme_info(\n",
    "    excelName,\n",
    "    \"Sheet1: Dataframe of chemicals detected as outliers using the robust MD method\",\n",
    ")\n",
    "\n",
    "w_excel(\n",
    "    path_to_file=outputs_dir,\n",
    "    filename=excelName,\n",
    "    dict_data_to_write={\n",
    "        \"Sheet1\": df_outliers,\n",
    "    },\n",
    "    readme_info=(\"readme\", df_readme),\n",
    "    #     ExcelWriter_kwargs={\"engine\": \"openpyxl\", \"encoding\": \"UTF-8\"}\n",
    "    #     startrow=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'category_regrouped' and ploting the size of each group on a barh plot (in one line)\n",
    "df_base_full_wCAS_woOutliersRMDk9a5 = outlier_detectors.make_full_df_after_outlier_detection_method(\n",
    "    df_to_detect_RMDm, df_clean_metNtlNpr_RMDm\n",
    ")\n",
    "internal_funcs.plot_categories(\n",
    "    df_in=df_base_full_wCAS_woOutliersRMDk9a5,\n",
    "    groupby=\"category_regrouped\",\n",
    "    color=\"darkorange\",\n",
    "    fontsize=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_funcs.plot_categories(\n",
    "#     df_in=df_base_full_wCAS_woOutliersRMDk9a5,\n",
    "#     df_in=df_analysis,\n",
    "#         df_in=df_base_full, \n",
    "#     df_in=df_base_full_wCAS,\n",
    "    df_in=df_cpc33to36, \n",
    "    groupby=\"activity_ISICclass\",\n",
    "    cutoff_value=10,\n",
    "    color=\"gray\",\n",
    "    fontsize=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cpc33to36[df_cpc33to36.activity_ISICclass==\"1920:Manufacture of refined petroleum products\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(df_base_full_wCAS_woOutliersRMDk9a5.activity_ISICclass.unique())\n",
    "# sorted(df_base_full_wCAS.activity_ISICclass.unique())\n",
    "# sorted(df_analysis.activity_ISICclass.unique())\n",
    "sorted(df_base_full.activity_ISICclass.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base_full_wCAS_woOutliersRMDk9a5.shape\n",
    "df_base_full_wCAS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base_full_wCAS_woOutliersRMDk9a5[\n",
    "#     df_base_full_wCAS_woOutliersRMDk9a5.activity_ISICclass.isin(\n",
    "# df_base_full_wCAS[\n",
    "#     df_base_full_wCAS.activity_ISICclass.isin(\n",
    "df_base_full[\n",
    "    df_base_full.activity_ISICclass.isin(\n",
    "        [\n",
    "            '0891:Mining of chemical and fertilizer minerals',\n",
    "#             \"2011:Manufacture of basic chemicals\", # 361\n",
    "#             \"2011a: Manufacture of nuclear fuels\", # 5\n",
    "#             \"2012:Manufacture of fertilizers and nitrogen compounds\", # 11\n",
    "#             \"2013:Manufacture of plastics and synthetic rubber in primary forms\", # 37\n",
    "#             \"2021:Manufacture of pesticides and other agrochemical products\", # 20\n",
    "#             \"2023:Manufacture of soap and detergents, cleaning and polishing preparations, pe\", # 7\n",
    "#             \"2029:Manufacture of other chemical products n.e.c.\", # 4\n",
    "#             \"20:Manufacture of chemicals and chemical products\", # 2\n",
    "        ]\n",
    "    )\n",
    "]#.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### apply Tukey method to detect outliers (univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_to_detect_Tm = df_base_full\n",
    "df_to_detect_Tm = df_base_full_wCAS\n",
    "\n",
    "df_clean_tukey, df_outliers_tukey = outlier_detectors.tukey_method_bulk(\n",
    "    df_to_detect_Tm[lst_methods + lst_methods_TLs + [\"referenceProduct_price\"]],\n",
    "    outlier_detection_fence=\"tight\",\n",
    ")\n",
    "print(\"out of\", df_to_detect_Tm.shape[0], \"items\")\n",
    "print(\"Tukey univariate method detected:\")\n",
    "for i in df_outliers_tukey.columns:\n",
    "    print(\"in \", i, \">>>>> \", df_outliers_tukey[i].count(), \"outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### apply Mahalanobis Distance method to detect outliers depending on CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemical_cat = \"Organic chemical\"\n",
    "chemical_cat = \"Inorganic chemical\"\n",
    "# chemical_cat = \"Other chemical\"\n",
    "# df_to_detect_MDmCAT = df_base_full[df_base_full.category_regrouped==chemical_cat]\n",
    "df_to_detect_MDmCAT = df_base_full_wCAS[\n",
    "    df_base_full_wCAS.category_regrouped == chemical_cat\n",
    "]\n",
    "\n",
    "(\n",
    "    df_clean_metNtlNpr_MDmCAT,\n",
    "    df_outliers_metNtlNpr_MDmCAT,\n",
    "    more_metNtlNpr_MDmCAT,\n",
    ") = outlier_detectors.mahalanobis_method(\n",
    "    df_to_detect_MDmCAT[lst_methods + lst_methods_TLs + [\"referenceProduct_price\"]],\n",
    "    alpha=(1 - 0.95),\n",
    ")\n",
    "print(\"out of\", df_to_detect_MDmCAT.shape[0], \"items\")\n",
    "print(len(more_metNtlNpr_MDmCAT[0]), \"outliers detected\")\n",
    "\n",
    "outlier_detectors.make_full_df_after_outlier_detection_method(\n",
    "    df_to_detect_MDmCAT, df_outliers_metNtlNpr_MDmCAT\n",
    ")[\n",
    "    [\"referenceProduct\"]\n",
    "    + [lst_methods[0]]\n",
    "    + [lst_methods_TLs[0]]\n",
    "    + [\"referenceProduct_price\"]\n",
    "]\n",
    "\n",
    "# df_clean_metNtlNpr_MDmCAT.sort_values(by=\"('IPCC 2013 GWP 100a V1.03', 'IPCC GWP 100a', 'kg CO2 eq')\").tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_full_wCAS.loc[162:163]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Insight from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_insights = df_base_full_wCAS_woOutliersRMDk9a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_methods_TLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chemicals_tot = df_for_insights.shape[0]\n",
    "num_chemicals_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### * functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(ar):\n",
    "    \"\"\"Create df with empirical CDF data.\n",
    "    \n",
    "    eCDF - empirical Cumulative Distribution Function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ar: 1-D array-like\n",
    "        Input array, should be 1-D pandas series\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_out: DataFrame\n",
    "        Dataframe containing the original index of the input data with\n",
    "        - column, named as passed data, containing ordered input items, \n",
    "        - column, named \"counts\", containing the number of times each unique item appears\n",
    "        - column, named \"cumsum\", containing the cumulate sum of counts\n",
    "        - column, named \"Probability\", containing the cumulative probability of occurance of each item\n",
    "    \"\"\"\n",
    "    x, indices, counts = np.unique(ar, return_index=True, return_counts=True)\n",
    "    cusum = np.cumsum(counts)\n",
    "    prob = cusum / cusum[-1] \n",
    "    df_out = pd.DataFrame({ar.name: x, \"counts\": counts, \"cumsum\": cusum, \"Probability\": prob}, index=indices)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def conjunction(*conditions):\n",
    "    \"\"\"All conditions met at the same time\"\"\"\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "def disjunction(*conditions):\n",
    "    \"\"\"Any condition met\"\"\"\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## % of chemicals transgressing at least one PB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = df_for_insights[lst_methods_TLs[0]] > 1\n",
    "c2 = df_for_insights[lst_methods_TLs[1]] > 1\n",
    "c3 = df_for_insights[lst_methods_TLs[2]] > 1\n",
    "c4 = df_for_insights[lst_methods_TLs[3]] > 1\n",
    "c5 = df_for_insights[lst_methods_TLs[4]] > 1\n",
    "c6 = df_for_insights[lst_methods_TLs[5]] > 1\n",
    "c7 = df_for_insights[lst_methods_TLs[6]] > 1\n",
    "c8 = df_for_insights[lst_methods_TLs[7]] > 1\n",
    "c9 = df_for_insights[lst_methods_TLs[8]] > 1\n",
    "\n",
    "num_chemicals_trans_at_least_onePB = df_for_insights[\n",
    "    disjunction(c1, c2, c3, c4, c5, c6, c7, c8, c9)\n",
    "].shape[0]\n",
    "print(\n",
    "    \"{} of the chemicals transgress at least one PB, i.e., {}% of the dataset.\".format(\n",
    "        num_chemicals_trans_at_least_onePB,\n",
    "        round(num_chemicals_trans_at_least_onePB/num_chemicals_tot*100, 2)\n",
    "    )\n",
    ")\n",
    "\n",
    "# df_for_insights[disjunction(c1, c2, c3, c4, c5, c6, c7, c8, c9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## % of chemicals absolute sustainable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = df_for_insights[lst_methods_TLs[0]] <= 1\n",
    "c2 = df_for_insights[lst_methods_TLs[1]] <= 1\n",
    "c3 = df_for_insights[lst_methods_TLs[2]] <= 1\n",
    "c4 = df_for_insights[lst_methods_TLs[3]] <= 1\n",
    "c5 = df_for_insights[lst_methods_TLs[4]] <= 1\n",
    "c6 = df_for_insights[lst_methods_TLs[5]] <= 1\n",
    "c7 = df_for_insights[lst_methods_TLs[6]] <= 1\n",
    "c8 = df_for_insights[lst_methods_TLs[7]] <= 1\n",
    "c9 = df_for_insights[lst_methods_TLs[8]] <= 1\n",
    "\n",
    "num_chemicals_abs_sustainable = df_for_insights[\n",
    "    conjunction(c1, c2, c3, c4, c5, c6, c7, c8, c9)\n",
    "].shape[0]\n",
    "print(\n",
    "    \"{} of the chemicals are absolute sustainable ({}% of the dataset),\"\n",
    "    \" i.e., they don't transgress any of the PBs.\".format(\n",
    "        num_chemicals_abs_sustainable,\n",
    "        round(num_chemicals_abs_sustainable / num_chemicals_tot * 100, 2),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_for_insights[conjunction(c1, c2, c3, c4, c5, c6, c7, c8, c9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## % of chemicals transgressing all the PBs at the same time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = df_for_insights[lst_methods_TLs[0]] > 1\n",
    "c2 = df_for_insights[lst_methods_TLs[1]] > 1\n",
    "c3 = df_for_insights[lst_methods_TLs[2]] > 1\n",
    "c4 = df_for_insights[lst_methods_TLs[3]] > 1\n",
    "c5 = df_for_insights[lst_methods_TLs[4]] > 1\n",
    "c6 = df_for_insights[lst_methods_TLs[5]] > 1\n",
    "c7 = df_for_insights[lst_methods_TLs[6]] > 1\n",
    "c8 = df_for_insights[lst_methods_TLs[7]] > 1\n",
    "c9 = df_for_insights[lst_methods_TLs[8]] > 1\n",
    "\n",
    "num_chemicals_bad_in_allPBs = df_for_insights[\n",
    "    conjunction(c1, c2, c3, c4, c5, c6, c7, c8, c9)\n",
    "].shape[0]\n",
    "print(\n",
    "    \"{} of the chemicals trasnsgress all the PBs simultaneously ({}% of the dataset)\".format(\n",
    "        num_chemicals_bad_in_allPBs,\n",
    "        round(num_chemicals_bad_in_allPBs / num_chemicals_tot * 100, 2),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_for_insights[conjunction(c1, c2, c3, c4, c5, c6, c7, c8, c9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## % of chemicals transgressing each PB? (or above/below any value of TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_of_interest = lst_methods_TLs[5]\n",
    "df = df_for_insights[cat_of_interest]\n",
    "\n",
    "df_out = ecdf(df)\n",
    "\n",
    "stored_indices = []  # they are indices of df_out, not df\n",
    "indices_duplicated_scores = []  # they are indices of df_out, not df\n",
    "\n",
    "for ix in df_out.index:\n",
    "    if df_out[df.name][ix] <= 1:\n",
    "        print_prob = df_out.Probability[ix]\n",
    "        print_item = df_out[df.name][ix]\n",
    "        stored_indices.append(ix)\n",
    "    if df_out.counts[ix] != 1:\n",
    "        indices_duplicated_scores.append(ix)\n",
    "\n",
    "# find the chemicals in the original df (translate indices from df_out to df)\n",
    "# for stored_indices:\n",
    "df_from_stored_indices = df_for_insights[\n",
    "    df_for_insights[cat_of_interest].isin(df_out[cat_of_interest][stored_indices])\n",
    "]\n",
    "\n",
    "# for indices_duplicated_scores:\n",
    "df_from_duplicated_scores = df_for_insights[\n",
    "    df_for_insights[cat_of_interest].isin(\n",
    "        df_out[cat_of_interest][indices_duplicated_scores]\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"set of chemicals not transgressing the PB: {} of {}\".format(\n",
    "        df_from_stored_indices.shape[0], df_for_insights.shape[0]\n",
    "    )\n",
    ")\n",
    "print(\"Probability of the set:\", np.round(print_prob, 3))\n",
    "print(\"Max value of TL included in set, max(TL)=\", print_item)\n",
    "\n",
    "print(\n",
    "    \"{} % of chemicals are transgesssed in {}\".format(\n",
    "        np.round((1 - print_prob) * 100, 2), df.name\n",
    "    )\n",
    ")\n",
    "\n",
    "# visualize the data (uncomment)\n",
    "# df_from_duplicated_scores\n",
    "df_from_stored_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## maximum/minimum TL for each PB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_insights[lst_methods_TLs].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_insights[lst_methods_TLs].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_insights[lst_methods_TLs].max()/df_for_insights[lst_methods_TLs].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_insights[df_for_insights.referenceProduct.isin(highlighted_product)][lst_methods_TLs].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## sort by specific TL for each PB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_insights.sort_values(by=lst_methods_TLs[4]).tail(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## For any PB: which chemicals transgress? to which category they belong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_for_insights[df_for_insights.referenceProduct.isin(highlighted_product)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctg = lst_methods_TLs[6] # Land-system change - Global !!!! NO TRANSGRESSED CHEMICALS\n",
    "# ctg = lst_methods_TLs[7] # Freshwater use - Global !!!! 7 transgressed\n",
    "# ctg = lst_methods_TLs[2] # Stratospheric ozone depletion !!!! 33 transgressed\n",
    "# ctg = lst_methods_TLs[4] # Biogeochemical flows - P !!!! 23 transgressed\n",
    "ctg = lst_methods_TLs[5] # Biogeochemical flows - N !!!! 126 transgressed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(ctg, \"\\n\")\n",
    "df_for_insights[df_for_insights[ctg] > 1].category_regrouped.unique()\n",
    "df_for_insights[df_for_insights[ctg] > 1].activity_ISICclass.unique()\n",
    "# sorted(df_for_insights[df_for_insights[lst_methods_TLs[5]]>1].referenceProduct_CPCclass.unique())\n",
    "\n",
    "internal_funcs.plot_categories(\n",
    "    df_for_insights[df_for_insights[ctg] > 1], # .between(1, 73.8, inclusive=True)\n",
    "#     groupby=\"referenceProduct_CPCclass\",\n",
    "    groupby=\"category_regrouped\",\n",
    "    cutoff_value=0,\n",
    ")\n",
    "\n",
    "# df_for_insights[df_for_insights[ctg].between(1, 73.8, inclusive=True)].sort_values(by=ctg) # .tail(10)\n",
    "\n",
    "# how many fixate N in their formula?\n",
    "N_regex = re.compile(\n",
    "    r\"(.*N[A-Z0-9].*)|(.*N$)\"\n",
    ")  # compiled regular expression for formulas with N\n",
    "\n",
    "formulas_with_N = []\n",
    "for i in df_for_insights[df_for_insights[ctg] > 1].sort_values(by=ctg).MF:\n",
    "    mo = N_regex.match(str(i))  # match object\n",
    "    if mo:\n",
    "        formulas_with_N.append(i) #mo.group())\n",
    "#         print(mo.group())\n",
    "print(round(\n",
    "    len(formulas_with_N)\n",
    "    / len(df_for_insights[df_for_insights[ctg] > 1].sort_values(by=ctg).MF)\n",
    "    * 100, 2\n",
    "),\"% fixate N directly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 38.1 % fixate N directly (48 chemicals in total)\n",
    "df_trnNflow = df_for_insights[df_for_insights[ctg] > 1]\n",
    "# to which classification they belong?\n",
    "df_trnNflow_fixateNdirectly = df_trnNflow[df_trnNflow.MF.isin(formulas_with_N)]\n",
    "df_trnNflow_fixateNdirectly\n",
    "# df_trnNflow_fixateNdirectly.referenceProduct_CPCclass.unique()\n",
    "# # how many of them belong to Fertilisers and pesticides (CPC: 346)?\n",
    "# df_trnNflow_fixateNdirectly[\n",
    "#     df_trnNflow_fixateNdirectly.referenceProduct_CPCclass.isin(\n",
    "#        [ \"34663: Herbicides, anti-sprouting products and plant-growth regulators\", \n",
    "#         '34653: Ammonium chloride; nitrites',\n",
    "#         '34662: Fungicides',]\n",
    "#     )\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_insights[df_for_insights[ctg] < 0].sort_values(by=ctg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_insights[df_for_insights[ctg].between(1, 73.8, inclusive=True)].sort_values(by=\"category_regrouped\").tail(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of Fertilizers and pesticides, directly related to agriculture and their TLs in BGC flows\n",
    "ddd = {}\n",
    "for i in df_for_insights.index:\n",
    "    if df_for_insights.referenceProduct_CPCclass[i].startswith(\n",
    "        \"346\"\n",
    "    ):  # Group 346 of CPC: Fertilizers and pesticides\n",
    "        ddd[i] = (\n",
    "            df_for_insights.referenceProduct_CPCclass[i],\n",
    "            df_for_insights.referenceProduct[i],\n",
    "            df_for_insights.MF[i],\n",
    "            df_for_insights[lst_methods_TLs[5]][i],\n",
    "            df_for_insights[lst_methods_TLs[4]][i],\n",
    "        )\n",
    "pd.DataFrame.from_dict(\n",
    "    ddd,\n",
    "    orient=\"index\",\n",
    "    columns=[\"CPC\", \"refProduct\", \"MF\", \"TL in N flow\", \"TL in P flow\"],\n",
    ").sort_values(by=\"TL in N flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## probability TL(EPC) > TL(GF) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TL_GF = {\n",
    "    \"TL in ('PBs-LCIA (baseline) V0.72', 'Climate change - CO2 concentration', 'ppm')\": 15.069444444444445,\n",
    "    \"TL in ('PBs-LCIA (baseline) V0.72', 'Climate change - Energy imbalance', 'Wm-2')\": 14.8,\n",
    "    \"TL in ('PBs-LCIA (baseline) V0.72', 'Stratospheric ozone depletion', 'DU')\": 0.4827586206896552,\n",
    "    \"TL in ('PBs-LCIA (baseline) V0.72', 'Ocean acidification', 'Omega Aragon')\": 4.811594202898551,\n",
    "    \"TL in ('PBs-LCIA (baseline) V0.72', 'Biogeochemical flows - P', 'Tg P')\": 2.1111111111111107,\n",
    "    \"TL in ('PBs-LCIA (baseline) V0.72', 'Biogeochemical flows - N', 'Tg N')\": 2.4193548387096775,\n",
    "    \"TL in ('PBs-LCIA (baseline) V0.72', 'Land-system change - Global', '%')\": 1.52,\n",
    "    \"TL in ('PBs-LCIA (baseline) V0.72', 'Freshwater use - Global', 'km3')\": 0.65,\n",
    "    \"TL in ('PBs-LCIA (baseline) V0.72', 'Change in biosphere integrity - BII loss', '% BII loss')\": 2.68,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_of_interest = lst_methods_TLs[8]\n",
    "df = df_for_insights[cat_of_interest]\n",
    "\n",
    "df_out = ecdf(df)\n",
    "\n",
    "stored_indices = []  # they are indices of df_out, not df\n",
    "indices_duplicated_scores = []  # they are indices of df_out, not df\n",
    "\n",
    "for ix in df_out.index:\n",
    "    if df_out[df.name][ix] <= TL_GF[cat_of_interest]:\n",
    "        print_prob = df_out.Probability[ix]\n",
    "        print_item = df_out[df.name][ix]\n",
    "        stored_indices.append(ix)\n",
    "    if df_out.counts[ix] != 1:\n",
    "        indices_duplicated_scores.append(ix)\n",
    "\n",
    "# find the chemicals in the original df (translate indices from df_out to df)\n",
    "# for stored_indices:\n",
    "df_from_stored_indices = df_for_insights[\n",
    "    df_for_insights[cat_of_interest].isin(df_out[cat_of_interest][stored_indices])\n",
    "]\n",
    "\n",
    "# for indices_duplicated_scores:\n",
    "df_from_duplicated_scores = df_for_insights[\n",
    "    df_for_insights[cat_of_interest].isin(\n",
    "        df_out[cat_of_interest][indices_duplicated_scores]\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"set of chemicals with TL_EPC lower than TL_GF ({}): {} of {}\".format(\n",
    "        TL_GF[cat_of_interest],\n",
    "        df_from_stored_indices.shape[0], \n",
    "        df_for_insights.shape[0]\n",
    "    )\n",
    ")\n",
    "print(\"Probability of the set:\", np.round(print_prob, 3))\n",
    "print(\"Max value of TL_EPC included in set, max(TL_EPC)=\", print_item)\n",
    "\n",
    "print(\n",
    "    \"{}% of chemicals with TL_EPC > TL_GF in {}\".format(\n",
    "        np.round((1 - print_prob) * 100, 2), \n",
    "        df.name\n",
    "    )\n",
    ")\n",
    "\n",
    "# visualize the data (uncomment)\n",
    "# df_from_duplicated_scores\n",
    "# df_from_stored_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_insights[df_for_insights.referenceProduct.isin(highlighted_product)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Find chemicals with absolute egalitarian sustainability (TL<=1) for df_TLs <--- based on df_clean!!!\n",
    "# Find chemicals with absolute status-quo sustainability (TL<=TL_statusquo) for df_TLs <--- based on df_clean!!!\n",
    " \n",
    "c0 = df_TLs.referenceProduct_price < 10\n",
    "c1 = (df_TLs[\"('PBs-LCIA (baseline) V0.72', 'Climate change - CO2 concentration', 'ppm')\"]<= TL_statusquo[\"Climate change - CO2 concentration\"])\n",
    "c2 = (df_TLs[\"('PBs-LCIA (baseline) V0.72', 'Climate change - Energy imbalance', 'Wm-2')\"]<= TL_statusquo[\"Climate change - Energy imbalance\"])\n",
    "c3 = (df_TLs[\"('PBs-LCIA (baseline) V0.72', 'Stratospheric ozone depletion', 'DU')\"]<= TL_statusquo[\"Stratospheric ozone depletion\"])\n",
    "c4 = (df_TLs[\"('PBs-LCIA (baseline) V0.72', 'Ocean acidification', 'Omega Aragon')\"]<= TL_statusquo[\"Ocean acidification\"])\n",
    "c5 = (df_TLs[\"('PBs-LCIA (baseline) V0.72', 'Biogeochemical flows - P', 'Tg P')\"] <= TL_statusquo[\"Biogeochemical flows - P\"])\n",
    "c6 = (df_TLs[\"('PBs-LCIA (baseline) V0.72', 'Biogeochemical flows - N', 'Tg N')\"] <= TL_statusquo[\"Biogeochemical flows - N\"])\n",
    "c7 = (df_TLs[\"('PBs-LCIA (baseline) V0.72', 'Land-system change - Global', '%')\"] <= TL_statusquo[\"Land-system change - Global\"])\n",
    "c8 = (df_TLs[\"('PBs-LCIA (baseline) V0.72', 'Freshwater use - Global', 'km3')\"] <= TL_statusquo[\"Freshwater use - Global\"])\n",
    "c9 = (df_TLs[\"('PBs-LCIA (baseline) V0.72', 'Change in biosphere integrity - BII loss', '% BII loss')\"]<= TL_statusquo[\"Change in biosphere integrity - BII loss\"])\n",
    "\n",
    "df_TLs[conjunction(\n",
    "#     c0, \n",
    "    c1, \n",
    "    c2, \n",
    "    c3, \n",
    "    c4, \n",
    "    c5, \n",
    "    c6, \n",
    "    c7, \n",
    "    c8, \n",
    "    c9\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(highlighted_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OUTPUTS: Export data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL\n",
    "# Make df of lst_metadata, lst_methods_TLs and lst_methods for later export\n",
    "\n",
    "df_metadata = pd.DataFrame(lst_metadata, columns=[\"lst_metadata\"])\n",
    "df_methods_TLs = pd.DataFrame(lst_methods_TLs, columns=[\"lst_methods_TLs\"]) \n",
    "df_methods = pd.DataFrame(lst_methods, columns=[\"lst_methods\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set output directory\n",
    "outputs_dir = set_outputs_dir(use_default=True)  # default `..\\data\\interim`\n",
    "\n",
    "## Export dataframe to excel\n",
    "excelName = \"temp-df_base_full_wCAS_woOutliersRMDk9a5.xlsx\"\n",
    "\n",
    "df_readme = make_readme_info(\n",
    "    excelName,\n",
    "    \"Temporal output from 0.30-to-0.83.ipynb. \\n\"\n",
    "    \"Is used for plotting\\n\"\n",
    "    \"Will have to be split later...\",\n",
    ")\n",
    "\n",
    "w_excel(\n",
    "    path_to_file=outputs_dir,\n",
    "    filename=excelName,\n",
    "    dict_data_to_write={\n",
    "        \"Sheet1\": df_base_full_wCAS_woOutliersRMDk9a5,\n",
    "        \"highlighted_product\": df_highlighted_product,\n",
    "        \"lst_metadata\" : df_metadata,\n",
    "        \"lst_methods_TLs\": df_methods_TLs,\n",
    "        \"lst_methods\": df_methods,\n",
    "    },\n",
    "    readme_info=(\"readme\", df_readme),\n",
    "    #     ExcelWriter_kwargs={\"engine\": \"openpyxl\", \"encoding\": \"UTF-8\"}\n",
    "    #     startrow=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set output directory\n",
    "outputs_dir = set_outputs_dir(use_default=True)  # default `..\\data\\interim`\n",
    "\n",
    "## Export dataframe to excel\n",
    "excelName = \"temp-df_base_full_wCAS.xlsx\"\n",
    "\n",
    "df_readme = make_readme_info(\n",
    "    excelName,\n",
    "    \"Temporal output from 0.30-to-0.83.ipynb. \\n\"\n",
    "    \"Is used for plotting\\n\"\n",
    "    \"Will have to be split later...\",\n",
    ")\n",
    "\n",
    "w_excel(\n",
    "    path_to_file=outputs_dir,\n",
    "    filename=excelName,\n",
    "    dict_data_to_write={\n",
    "        \"Sheet1\": df_base_full_wCAS,\n",
    "        \"highlighted_product\": df_highlighted_product,\n",
    "        \"lst_metadata\" : df_metadata,\n",
    "        \"lst_methods_TLs\": df_methods_TLs,\n",
    "        \"lst_methods\": df_methods,        \n",
    "    },\n",
    "    readme_info=(\"readme\", df_readme),\n",
    "    #     ExcelWriter_kwargs={\"engine\": \"openpyxl\", \"encoding\": \"UTF-8\"}\n",
    "    #     startrow=0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (proj17)",
   "language": "python",
   "name": "17-conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
